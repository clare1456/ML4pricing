{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer to minibatches\n",
    "\n",
    "* mini_batch: pd.DataFrame[\"node_features\", \"column_features\", \"edges\", \"dual_offsets\"]\n",
    "  * \"node_features\" : (node_num, node_feature_dim)\n",
    "  * \"column_features\" : (column_num, column_feature_dim)\n",
    "  * \"edges\" : (2, column_num*column_path_length) [ [ node_idx ], [ column_idx ] ] \n",
    "  * \"dual_offsets\" : (node_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"D:\\Code\\ML4pricing\\CGAlgs\")\n",
    "from CGAlgs import GraphTool\n",
    "\n",
    "def pack_mini_batches(graph_file_path, iter_file_path):\n",
    "    graph = GraphTool.Graph(graph_file_path)\n",
    "    iterFile = json.load(open(iter_file_path, \"r\"))[\"IterOfColumns\"] #!check key\n",
    "    mini_batches = []\n",
    "    for iter_name, iter_data in iterFile.items():\n",
    "        columns = iter_data[\"columns\"] #!check key\n",
    "        duals = np.array(iter_data[\"dual\"]) #!check key\n",
    "        dual_offsets = np.array(iter_data[\"offset\"]) #!check key\n",
    "        # 特征工程\n",
    "        ## node_features\n",
    "        node_features = [] \n",
    "        for i in range(graph.nodeNum):\n",
    "            node_feature = [duals[i], graph.locations[i][0], graph.locations[i][1], graph.demand[i], graph.readyTime[i], graph.dueTime[i]] # dim = 6\n",
    "            node_features.append(node_feature)\n",
    "        node_features = np.array(node_features)\n",
    "        ## column_features\n",
    "        column_features = []\n",
    "        for ci, column in enumerate(columns):\n",
    "            path = column[\"path\"][:-1] + [0] # change terminal idx #!check key\n",
    "            dualSum = sum(duals[path])\n",
    "            demand = sum(graph.demand[path])\n",
    "            distance = sum([graph.disMatrix[path[i]][path[i+1]] for i in range(len(path)-1)])\n",
    "            onehot_path = np.zeros(graph.nodeNum)\n",
    "            onehot_path[path] = 1\n",
    "            column_feature = [dualSum, demand, distance] + list(onehot_path) # dim = 3 + nodeNum\n",
    "            column_features.append(column_feature)\n",
    "        columnd_features = np.array(column_features)\n",
    "        ## edges\n",
    "        edges = [[], []]\n",
    "        for ci, column in enumerate(columns):\n",
    "            for ni in column[\"path\"][:-1]: #!check key\n",
    "                # node to column\n",
    "                edges[0].append(ni) \n",
    "                edges[1].append(ci) \n",
    "        # 保存数据\n",
    "        mini_batch = {\n",
    "            \"node_features\": node_features,\n",
    "            \"column_features\": column_features,\n",
    "            \"edges\": edges, \n",
    "            \"dual_offsets\": dual_offsets\n",
    "        }\n",
    "        mini_batches.append(mini_batch)\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义各个文件夹路径\n",
    "graph_folder_path = \"D:/Code/ML4pricing/data/graph/\" #! check path\n",
    "iter_folder_path = \"D:/Code/ML4pricing/data/iter/\" #! check path\n",
    "dataset_save_path = \"D:/Code/ML4pricing/data/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包单个算例数据\n",
    "file_name = \"\" # to set\n",
    "dataset_name = \"instance_\" + file_name\n",
    "graph_file_path = graph_folder_path + file_name + \".json\" \n",
    "iter_file_path = iter_folder_path + file_name + \".json\" \n",
    "mini_batches = pack_mini_batches(graph_file_path, iter_file_path)\n",
    "json.dump(mini_batches, open(dataset_save_path + dataset_name + \".json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包多个算例数据\n",
    "file_name_list = [] # to set\n",
    "dataset_name = \"instances_{}\".format(len(file_name_list))\n",
    "mini_batches = []\n",
    "for file_name in file_name_list:\n",
    "    graph_file_path = graph_folder_path + file_name + \".json\" \n",
    "    iter_file_path = iter_folder_path + file_name + \".json\" \n",
    "    mini_batches += pack_mini_batches(graph_file_path, iter_file_path)\n",
    "json.dump(mini_batches, open(dataset_save_path + dataset_name + \".json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
